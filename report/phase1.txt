Agent Selection & Justification

We selected AI Trip Planner because trip planning is a natural stress test for context and memory: users iteratively refine destinations, trip lengths, dates, and constraints, then expect the assistant to synthesize external facts (places, safety, transit) with situational data (weather by date/city) across many turns. This domain cleanly and necessarily exercises multiple tools—web knowledge for attraction/background lookup and a date-aware weather API—so we can construct request sets that meaningfully combine tools and expose redundant calls, missed calls, and context loss as conversations grow. It also maps directly to the rubric’s metrics: “task completion” can be adjudicated as producing a coherent, constraint-satisfying itinerary; “tool efficiency” can be quantified via unnecessary/redundant/omitted tool calls; and “response quality” can be judged by human raters familiar with travel. Finally, a cloud-hosted chat application with per-session state and per-user isolation aligns with the deployment requirements, while the agent’s modular runtime (LLM + tools + context windowing) provides a crisp Phase 1 baseline without long-term memory and a clear path to Phase 2 improvements (summarization, preference extraction, memory injection, and tool selection under context budget).